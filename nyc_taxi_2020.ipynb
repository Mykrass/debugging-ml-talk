{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxicab \"Drift\" Example\n",
    "\n",
    "Author: shreyashankar\n",
    "\n",
    "This notebook shows a toy example of a machine learning model that achieves similar performance on the train and evaluation sets but experiences performance \"degradation\" when simulating a \"live\" deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.ensemble import RandomForestClassifier\n",
    "from cuml.metrics import roc_auc_score\n",
    "from dask.array import from_array\n",
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "from progress import progress\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import dask_cudf\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "n_workers = 3\n",
    "\n",
    "numeric_feat = [\n",
    "    \"pickup_weekday\",\n",
    "    \"pickup_hour\",\n",
    "    'work_hours',\n",
    "    \"pickup_minute\",\n",
    "    \"passenger_count\",\n",
    "    'trip_distance',\n",
    "    'trip_time',\n",
    "    'trip_speed'\n",
    "]\n",
    "categorical_feat = [\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"RatecodeID\",\n",
    "]\n",
    "features = numeric_feat + categorical_feat\n",
    "\n",
    "EPS = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize cluster\n",
    "\n",
    "Using Saturn's predefined cluster setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-11 02:14:09] INFO - dask-saturn | Cluster is ready\n",
      "[2021-02-11 02:14:09] INFO - dask-saturn | Registering default plugins\n",
      "[2021-02-11 02:14:09] INFO - dask-saturn | {'tcp://10.0.25.24:37137': {'status': 'repeat'}, 'tcp://10.0.4.201:38121': {'status': 'repeat'}, 'tcp://10.0.9.1:39615': {'status': 'repeat'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://d-shrey-rapids-random-forest-85ae247e8459473fbfdc641eb0e7ecb2.main-namespace:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='https://d-shrey-rapids-random-forest-85ae247e8459473fbfdc641eb0e7ecb2.community.saturnenterprise.io' target='_blank'>https://d-shrey-rapids-random-forest-85ae247e8459473fbfdc641eb0e7ecb2.community.saturnenterprise.io</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>46.50 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.0.13.234:8786' processes=3 threads=12, memory=46.50 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "progress('rf-rapids-dask-cluster-setup')\n",
    "cluster = SaturnCluster(\n",
    "    n_workers=n_workers, scheduler_size=\"medium\", worker_size=\"g4dnxlarge\"\n",
    ")\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: dask_cudf.DataFrame, target_col: str, start_date: str = None, end_date: str = None) -> dask_cudf.DataFrame:\n",
    "    \"\"\"\n",
    "    This function computes the target ('high_tip'), adds features, and removes unused features.\n",
    "    Note that zero EDA or cleaning is performed here, whereas in the \"real world\" you should definitely\n",
    "    inspect and clean the data. If a start or end date is specified, any entries outside of these bounds\n",
    "    will be dropped from the dataframe.\n",
    "    \n",
    "    Args:\n",
    "        df: dask dataframe representing data\n",
    "        target_col: column name of the target (must be in df)\n",
    "        start_date (optional): minimum date in the resulting dataframe\n",
    "        end_date (optional): maximum date in the resulting dataframe\n",
    "    \n",
    "    Returns:\n",
    "        dask_cudf: DataFrame representing the preprocessed dataframe\n",
    "    \"\"\"\n",
    "    # Basic cleaning\n",
    "    df = df[df.fare_amount > 0]  # avoid divide-by-zero\n",
    "    if start_date:\n",
    "        df = df[df.tpep_dropoff_datetime.astype('str') >= start_date]\n",
    "    if end_date:\n",
    "        df = df[df.tpep_dropoff_datetime.astype('str') <= end_date]\n",
    "\n",
    "    # add target\n",
    "    df[\"tip_fraction\"] = df.tip_amount / df.fare_amount\n",
    "    df[target_col] = df[\"tip_fraction\"] > 0.2\n",
    "\n",
    "    # add features\n",
    "    df[\"pickup_weekday\"] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df[\"pickup_hour\"] = df.tpep_pickup_datetime.dt.hour\n",
    "    df[\"pickup_minute\"] = df.tpep_pickup_datetime.dt.minute\n",
    "    df[\"work_hours\"] = (df.pickup_weekday >= 0) & (df.pickup_weekday <= 4) & (df.pickup_hour >= 8) & (df.pickup_hour <= 18)\n",
    "    df['trip_time'] = (df.tpep_dropoff_datetime - df.tpep_pickup_datetime).dt.seconds\n",
    "    df['trip_speed'] = df.trip_distance / (df.trip_time + EPS)\n",
    "\n",
    "    # drop unused columns\n",
    "    df = df[['tpep_dropoff_datetime'] + features + [target_col]]\n",
    "    df[features + [target_col]] = df[features + [target_col]].astype(\"float32\").fillna(-1.0)\n",
    "\n",
    "    # convert target to int32 for efficiency (it's just 0s and 1s)\n",
    "    df[target_col] = df[target_col].astype(\"int32\")\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def f1_streaming(df: dask_cudf.DataFrame, target_col: str, pred_col: str) -> dask_cudf.Series:\n",
    "    \"\"\"\n",
    "    Computes rolling precision and recall columns\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    Precision: of the rows we predicted true, how many were true?\n",
    "    Recall: of all the trues, how many did we predict to be true?\n",
    "    \n",
    "    Args:\n",
    "        df: dask dataframe\n",
    "        target_col: column name of the target (must be in df)\n",
    "        pred_col: column name of the prediction (must be in df)\n",
    "    \n",
    "    Returns:\n",
    "        dask_cudf: Series representing the cumulative F1 score\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=['tpep_dropoff_datetime'], ascending=True)\n",
    "    numerator = (df['prediction'] & df[target_col]).cumsum()\n",
    "    precision_denominator = df['prediction'].cumsum()\n",
    "    recall_denominator = df[target_col].cumsum()\n",
    "    precision = numerator / precision_denominator\n",
    "    recall = numerator / recall_denominator\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def get_daily_f1_score(partition):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    numerator = (partition[target_col] & partition['prediction']).sum()\n",
    "    recall_denominator = partition[target_col].sum()\n",
    "    precision_denominator = partition['prediction'].sum()\n",
    "    precision = numerator / precision_denominator\n",
    "    recall = numerator / recall_denominator\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    partition['daily_f1'] = f1_score\n",
    "    return partition.sort_values(by='tpep_dropoff_datetime', ascending=False).head(1)[['day', 'rolling_f1', 'daily_f1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data\n",
    "\n",
    "The training window is all of January 2020 and accessible via a public s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 6405008, Size: 0.903424059 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:28:15</td>\n",
       "      <td>2020-01-01 00:33:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:35:39</td>\n",
       "      <td>2020-01-01 00:43:04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:47:41</td>\n",
       "      <td>2020-01-01 00:53:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:55:23</td>\n",
       "      <td>2020-01-01 01:00:14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-01 00:01:58</td>\n",
       "      <td>2020-01-01 00:04:16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0       1.0  2020-01-01 00:28:15   2020-01-01 00:33:03              1.0   \n",
       "1       1.0  2020-01-01 00:35:39   2020-01-01 00:43:04              1.0   \n",
       "2       1.0  2020-01-01 00:47:41   2020-01-01 00:53:52              1.0   \n",
       "3       1.0  2020-01-01 00:55:23   2020-01-01 01:00:14              1.0   \n",
       "4       2.0  2020-01-01 00:01:58   2020-01-01 00:04:16              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.2         1.0                  N         238.0         239.0   \n",
       "1            1.2         1.0                  N         239.0         238.0   \n",
       "2            0.6         1.0                  N         238.0         238.0   \n",
       "3            0.8         1.0                  N         238.0         151.0   \n",
       "4            0.0         1.0                  N         193.0         193.0   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           1.0          6.0    3.0      0.5        1.47           0.0   \n",
       "1           1.0          7.0    3.0      0.5        1.50           0.0   \n",
       "2           1.0          6.0    3.0      0.5        1.00           0.0   \n",
       "3           1.0          5.5    0.5      0.5        1.36           0.0   \n",
       "4           2.0          3.5    0.5      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3         11.27                   2.5  \n",
       "1                    0.3         12.30                   2.5  \n",
       "2                    0.3         10.80                   2.5  \n",
       "3                    0.3          8.16                   0.0  \n",
       "4                    0.3          4.80                   0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2020-01.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "print(f\"Num rows: {len(taxi)}, Size: {taxi.memory_usage(deep=True).sum().compute() / 1e9} GB\")\n",
    "taxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 6382762, Size: 0.357434672 GB\n"
     ]
    }
   ],
   "source": [
    "target_col = \"high_tip\"\n",
    "\n",
    "taxi_train = preprocess(df=taxi, target_col=target_col)\n",
    "print(f\"Num rows: {len(taxi_train)}, Size: {taxi_train.memory_usage(deep=True).sum().compute() / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "We will fit a random forest with 100 estimators and `max_depth` of 10 to the training set. Zero hyperparameter tuning is done here. If we were to do any hyperparameter tuning, we should use a hold-out validation set.\n",
    "\n",
    "We train the model on GPU and evaluate on CPU. We evaluate the model using the [F1 score](https://en.wikipedia.org/wiki/F-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 257 ms, sys: 3.12 ms, total: 261 ms\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "progress('start-rf-rapids-dask-fit')\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, ignore_empty_partitions=True)\n",
    "\n",
    "rfc.fit(taxi_train[features], taxi_train[target_col])\n",
    "progress('finished-rf-rapids-dask-fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6681650475249482\n",
      "CPU times: user 3.87 s, sys: 307 ms, total: 4.17 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute F1 \n",
    "# This is (relatively) slow since we are copying data to the CPU to compute the metric.\n",
    "\n",
    "preds = rfc.predict_proba(taxi_train[features])[1]\n",
    "print(f'F1: {f1_score(taxi_train[target_col].compute().to_array(), preds.round().compute().to_array())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set\n",
    "\n",
    "The test window is all of February 2020 and also accessible via public s3 bucket. The F1 scores are similar between train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_feb = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2020-02.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "taxi_test = preprocess(taxi_feb, target_col=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6658098920024954\n"
     ]
    }
   ],
   "source": [
    "# Compute F1 on test set\n",
    "# This is slow since we are copying data to the CPU to compute the metric.\n",
    "\n",
    "preds = rfc.predict_proba(taxi_test[features])[1]\n",
    "print(f'F1: {f1_score(taxi_test[target_col].compute().to_array(), preds.round().compute().to_array())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate \"live\" inference on March\n",
    "\n",
    "As every new batch of points comes in, we make a prediction. We compute the rolling (F1 score since March 1) and daily F1 scores. Note that the daily F1 score drops significantly, but this performance degradation is not so pronounced if we just monitor the rolling F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load and sort the march dataframe\n",
    "\n",
    "taxi_march = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2020-03.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "taxi_inference = preprocess(taxi_march, target_col=target_col, start_date='2020-03-01', end_date='2020-03-31').sort_values(by=['tpep_dropoff_datetime'], ascending=True).reset_index(drop=True)\n",
    "taxi_inference['day'] = taxi_inference.tpep_dropoff_datetime.dt.day.to_dask_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as a new column, compute rolling F1 score\n",
    "\n",
    "taxi_inference['predicted_prob'] = rfc.predict_proba(taxi_inference[features])[1]\n",
    "taxi_inference['prediction'] = taxi_inference['predicted_prob'].round().astype('int32')\n",
    "taxi_inference['rolling_f1'] = f1_streaming(taxi_inference, target_col, 'prediction')\n",
    "daily_f1 = taxi_inference.groupby('day').apply(get_daily_f1_score, meta={'day': int, 'rolling_f1': float, 'daily_f1': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>rolling_f1</th>\n",
       "      <th>daily_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178123</th>\n",
       "      <td>1</td>\n",
       "      <td>0.576629</td>\n",
       "      <td>0.576629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370840</th>\n",
       "      <td>2</td>\n",
       "      <td>0.633320</td>\n",
       "      <td>0.677398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592741</th>\n",
       "      <td>3</td>\n",
       "      <td>0.649983</td>\n",
       "      <td>0.675877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821398</th>\n",
       "      <td>4</td>\n",
       "      <td>0.659940</td>\n",
       "      <td>0.684125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064741</th>\n",
       "      <td>5</td>\n",
       "      <td>0.675841</td>\n",
       "      <td>0.722298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307013</th>\n",
       "      <td>6</td>\n",
       "      <td>0.682284</td>\n",
       "      <td>0.708181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58517</th>\n",
       "      <td>7</td>\n",
       "      <td>0.668002</td>\n",
       "      <td>0.555498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225439</th>\n",
       "      <td>8</td>\n",
       "      <td>0.659918</td>\n",
       "      <td>0.572543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400352</th>\n",
       "      <td>9</td>\n",
       "      <td>0.660947</td>\n",
       "      <td>0.670717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583448</th>\n",
       "      <td>10</td>\n",
       "      <td>0.661801</td>\n",
       "      <td>0.670428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765578</th>\n",
       "      <td>11</td>\n",
       "      <td>0.663678</td>\n",
       "      <td>0.684011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936075</th>\n",
       "      <td>12</td>\n",
       "      <td>0.667420</td>\n",
       "      <td>0.711109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070221</th>\n",
       "      <td>13</td>\n",
       "      <td>0.668812</td>\n",
       "      <td>0.691889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159620</th>\n",
       "      <td>14</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.571661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219523</th>\n",
       "      <td>15</td>\n",
       "      <td>0.664177</td>\n",
       "      <td>0.564885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283501</th>\n",
       "      <td>16</td>\n",
       "      <td>0.663604</td>\n",
       "      <td>0.638491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328995</th>\n",
       "      <td>17</td>\n",
       "      <td>0.663178</td>\n",
       "      <td>0.635958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365063</th>\n",
       "      <td>18</td>\n",
       "      <td>0.662761</td>\n",
       "      <td>0.628822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394730</th>\n",
       "      <td>19</td>\n",
       "      <td>0.662613</td>\n",
       "      <td>0.648809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422146</th>\n",
       "      <td>20</td>\n",
       "      <td>0.662300</td>\n",
       "      <td>0.629325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438271</th>\n",
       "      <td>21</td>\n",
       "      <td>0.661760</td>\n",
       "      <td>0.534262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448533</th>\n",
       "      <td>22</td>\n",
       "      <td>0.661437</td>\n",
       "      <td>0.541612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462011</th>\n",
       "      <td>23</td>\n",
       "      <td>0.661225</td>\n",
       "      <td>0.611136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473783</th>\n",
       "      <td>24</td>\n",
       "      <td>0.660991</td>\n",
       "      <td>0.594909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484934</th>\n",
       "      <td>25</td>\n",
       "      <td>0.660754</td>\n",
       "      <td>0.590316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495523</th>\n",
       "      <td>26</td>\n",
       "      <td>0.660534</td>\n",
       "      <td>0.596606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507234</th>\n",
       "      <td>27</td>\n",
       "      <td>0.660228</td>\n",
       "      <td>0.576993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514827</th>\n",
       "      <td>28</td>\n",
       "      <td>0.659934</td>\n",
       "      <td>0.501860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520358</th>\n",
       "      <td>29</td>\n",
       "      <td>0.659764</td>\n",
       "      <td>0.537860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529847</th>\n",
       "      <td>30</td>\n",
       "      <td>0.659530</td>\n",
       "      <td>0.576178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         day  rolling_f1  daily_f1\n",
       "178123     1    0.576629  0.576629\n",
       "370840     2    0.633320  0.677398\n",
       "592741     3    0.649983  0.675877\n",
       "821398     4    0.659940  0.684125\n",
       "1064741    5    0.675841  0.722298\n",
       "1307013    6    0.682284  0.708181\n",
       "58517      7    0.668002  0.555498\n",
       "225439     8    0.659918  0.572543\n",
       "400352     9    0.660947  0.670717\n",
       "583448    10    0.661801  0.670428\n",
       "765578    11    0.663678  0.684011\n",
       "936075    12    0.667420  0.711109\n",
       "1070221   13    0.668812  0.691889\n",
       "1159620   14    0.666032  0.571661\n",
       "1219523   15    0.664177  0.564885\n",
       "1283501   16    0.663604  0.638491\n",
       "1328995   17    0.663178  0.635958\n",
       "1365063   18    0.662761  0.628822\n",
       "1394730   19    0.662613  0.648809\n",
       "1422146   20    0.662300  0.629325\n",
       "1438271   21    0.661760  0.534262\n",
       "1448533   22    0.661437  0.541612\n",
       "1462011   23    0.661225  0.611136\n",
       "1473783   24    0.660991  0.594909\n",
       "1484934   25    0.660754  0.590316\n",
       "1495523   26    0.660534  0.596606\n",
       "1507234   27    0.660228  0.576993\n",
       "1514827   28    0.659934  0.501860\n",
       "1520358   29    0.659764  0.537860\n",
       "1529847   30    0.659530  0.576178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_f1.sort_values(by='day', ascending=True).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on later months\n",
    "\n",
    "We see the performance drop in March 2020, but what happens for future months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading month 2020-03 for the first time.\n",
      "2020-03\n",
      "\tF1: 0.6592796100378214\n",
      "Loading month 2020-04 for the first time.\n",
      "2020-04\n",
      "\tF1: 0.5714705472990737\n",
      "Loading month 2020-05 for the first time.\n",
      "2020-05\n",
      "\tF1: 0.5530868473460906\n",
      "Loading month 2020-06 for the first time.\n",
      "2020-06\n",
      "\tF1: 0.5967621469282887\n"
     ]
    }
   ],
   "source": [
    "# Cycle through many test sets\n",
    "\n",
    "months = ['2020-03', '2020-04', '2020-05', '2020-06']\n",
    "month_dfs = {}\n",
    "\n",
    "for month in months:\n",
    "    \n",
    "    if month not in month_dfs:\n",
    "        print(f'Loading month {month} for the first time.')\n",
    "        df = dask_cudf.read_csv(\n",
    "            f\"s3://nyc-tlc/trip data/yellow_tripdata_{month}.csv\",\n",
    "            parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "            storage_options={\"anon\": True},\n",
    "            assume_missing=True,\n",
    "        )\n",
    "\n",
    "        df = preprocess(df, target_col=target_col)\n",
    "        month_dfs[month] = df.copy()\n",
    "    \n",
    "    curr_taxi_test = month_dfs[month]\n",
    "        \n",
    "    preds = rfc.predict_proba(curr_taxi_test[features])[1]\n",
    "    print(month)\n",
    "    print(f'\\tF1: {f1_score(curr_taxi_test[target_col].compute().to_array(), preds.round().compute().to_array())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect differences between feature values\n",
    "\n",
    "Maybe the distribution of data shifted. We could try to quantify this using a 2-sided statistical test (Kolmogorov Smirnov in this example)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare January 2020 vs February 2020\n",
    "\n",
    "This snippet shows that the p values being small doesn't really tell us much, as we get very small p values when comparing January 2020 vs February 2020 even though we know the F1 score was similar. Curse \"big data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = []\n",
    "p_values = []\n",
    "\n",
    "for feature in features:\n",
    "    statistic, p_value = stats.ks_2samp(taxi_train[feature].compute().to_pandas(), taxi_test[feature].compute().to_pandas())\n",
    "    statistics.append(statistic)\n",
    "    p_values.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pickup_weekday</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work_hours</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trip_speed</td>\n",
       "      <td>0.035415</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>8.610133e-258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>5.266602e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>2.994877e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>2.157559e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>2.634493e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>3.047481e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pickup_minute</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>8.861498e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  statistic        p_value\n",
       "0    pickup_weekday   0.046196   0.000000e+00\n",
       "2        work_hours   0.028587   0.000000e+00\n",
       "6         trip_time   0.017205   0.000000e+00\n",
       "7        trip_speed   0.035415   0.000000e+00\n",
       "1       pickup_hour   0.009676  8.610133e-258\n",
       "5     trip_distance   0.005312   5.266602e-78\n",
       "8      PULocationID   0.004083   2.994877e-46\n",
       "9      DOLocationID   0.003132   2.157559e-27\n",
       "4   passenger_count   0.002947   2.634493e-24\n",
       "10       RatecodeID   0.002616   3.047481e-19\n",
       "3     pickup_minute   0.000702   8.861498e-02"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame(data={'feature': features, 'statistic': statistics, 'p_value': p_values})\n",
    "comparison_df.sort_values(by='p_value', ascending=True).head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare January 2020 vs March 2020\n",
    "\n",
    "These p values are also small, which is good? But if this method in general sends warning alerts all the time, an end user might not trust it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = []\n",
    "p_values = []\n",
    "\n",
    "for feature in features:\n",
    "    statistic, p_value = stats.ks_2samp(taxi_train[feature].compute().to_pandas(), taxi_inference[feature].compute().to_pandas())\n",
    "    statistics.append(statistic)\n",
    "    p_values.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pickup_weekday</td>\n",
       "      <td>0.059051</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.017536</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.022485</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.017913</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trip_speed</td>\n",
       "      <td>0.030289</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>0.013995</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>0.013068</td>\n",
       "      <td>3.746619e-302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work_hours</td>\n",
       "      <td>0.010840</td>\n",
       "      <td>5.006014e-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>0.007507</td>\n",
       "      <td>5.385560e-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>0.005615</td>\n",
       "      <td>3.933726e-56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pickup_minute</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>3.722759e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  statistic        p_value\n",
       "0    pickup_weekday   0.059051   0.000000e+00\n",
       "1       pickup_hour   0.017536   0.000000e+00\n",
       "4   passenger_count   0.022485   0.000000e+00\n",
       "5     trip_distance   0.017913   0.000000e+00\n",
       "7        trip_speed   0.030289   0.000000e+00\n",
       "9      DOLocationID   0.013995   0.000000e+00\n",
       "8      PULocationID   0.013068  3.746619e-302\n",
       "2        work_hours   0.010840  5.006014e-208\n",
       "6         trip_time   0.007507  5.385560e-100\n",
       "10       RatecodeID   0.005615   3.933726e-56\n",
       "3     pickup_minute   0.000642   3.722759e-01"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame(data={'feature': features, 'statistic': statistics, 'p_value': p_values})\n",
    "comparison_df.sort_values(by='p_value', ascending=True).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
