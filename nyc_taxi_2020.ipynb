{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.ensemble import RandomForestClassifier\n",
    "from cuml.metrics import roc_auc_score\n",
    "from dask.array import from_array\n",
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "from progress import progress\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import dask_cudf\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "numeric_feat = [\n",
    "    \"pickup_weekday\",\n",
    "    \"pickup_hour\",\n",
    "    'work_hours',\n",
    "    \"pickup_minute\",\n",
    "    \"passenger_count\",\n",
    "    'trip_distance',\n",
    "    'trip_time',\n",
    "    'trip_speed'\n",
    "]\n",
    "categorical_feat = [\n",
    "    \"PULocationID\",\n",
    "    \"DOLocationID\",\n",
    "    \"RatecodeID\",\n",
    "]\n",
    "features = numeric_feat + categorical_feat\n",
    "\n",
    "EPS = 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2021-02-02 00:08:46] INFO - dask-saturn | Cluster is ready\n",
      "[2021-02-02 00:08:46] INFO - dask-saturn | Registering default plugins\n",
      "[2021-02-02 00:08:46] INFO - dask-saturn | {'tcp://10.0.0.100:35425': {'status': 'repeat'}, 'tcp://10.0.18.10:34943': {'status': 'repeat'}, 'tcp://10.0.27.175:41401': {'status': 'repeat'}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://d-shrey-rapids-random-forest-85ae247e8459473fbfdc641eb0e7ecb2.main-namespace:8786</li>\n",
       "  <li><b>Dashboard: </b><a href='https://d-shrey-rapids-random-forest-85ae247e8459473fbfdc641eb0e7ecb2.community.saturnenterprise.io' target='_blank'>https://d-shrey-rapids-random-forest-85ae247e8459473fbfdc641eb0e7ecb2.community.saturnenterprise.io</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>3</li>\n",
       "  <li><b>Cores: </b>12</li>\n",
       "  <li><b>Memory: </b>46.50 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.0.18.5:8786' processes=3 threads=12, memory=46.50 GB>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from progress import progress\n",
    "progress('rf-rapids-dask-cluster-setup')\n",
    "\n",
    "from dask.distributed import Client, wait\n",
    "from dask_saturn import SaturnCluster\n",
    "n_workers = 3\n",
    "cluster = SaturnCluster(\n",
    "    n_workers=n_workers, scheduler_size=\"medium\", worker_size=\"g4dnxlarge\"\n",
    ")\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: dask_cudf.DataFrame, target_col: str, start_date: str = None, end_date: str = None) -> dask_cudf.DataFrame:\n",
    "    \"\"\"\n",
    "        * computes the target ('high_tip')\n",
    "        * adds features\n",
    "        * removes unused features\n",
    "\n",
    "    Casts all numeric values to 32-bit types, for efficiency and\n",
    "    because some older versions of CUDA / ``cudf``, ``cuml``\n",
    "    did not support 64-bit types in training data.\n",
    "    \"\"\"\n",
    "    # Clean\n",
    "    df = df[df.fare_amount > 0]  # avoid divide-by-zero\n",
    "    if start_date:\n",
    "        df = df[df.tpep_dropoff_datetime.astype('str') >= start_date]\n",
    "    if end_date:\n",
    "        df = df[df.tpep_dropoff_datetime.astype('str') <= end_date]\n",
    "\n",
    "    # add target\n",
    "    df[\"tip_fraction\"] = df.tip_amount / df.fare_amount\n",
    "    df[target_col] = df[\"tip_fraction\"] > 0.2\n",
    "\n",
    "    # add features\n",
    "    df[\"pickup_weekday\"] = df.tpep_pickup_datetime.dt.weekday\n",
    "    df[\"pickup_hour\"] = df.tpep_pickup_datetime.dt.hour\n",
    "    df[\"pickup_minute\"] = df.tpep_pickup_datetime.dt.minute\n",
    "    df[\"work_hours\"] = (df.pickup_weekday >= 0) & (df.pickup_weekday <= 4) & (df.pickup_hour >= 8) & (df.pickup_hour <= 18)\n",
    "    df['trip_time'] = (df.tpep_dropoff_datetime - df.tpep_pickup_datetime).dt.seconds\n",
    "    df['trip_speed'] = df.trip_distance / (df.trip_time + EPS)\n",
    "\n",
    "    # drop unused columns\n",
    "    df = df[['tpep_dropoff_datetime'] + features + [target_col]]\n",
    "    df[features + [target_col]] = df[features + [target_col]].astype(\"float32\").fillna(-1.0)\n",
    "\n",
    "    # convert target to int32 for efficiency (it's just 0s and 1s)\n",
    "    df[target_col] = df[target_col].astype(\"int32\")\n",
    "\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def f1_streaming(df: dask_cudf.DataFrame, target_col: str, pred_col: str) -> dask_cudf.Series:\n",
    "    \"\"\"\n",
    "    Computes rolling precision and recall columns\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "    Precision: of the rows we predicted true, how many were true?\n",
    "    Recall: of all the trues, how many did we predict to be true?\n",
    "    \n",
    "    Args:\n",
    "        df: dask dataframe\n",
    "        target_col: column name of the target (must be in df)\n",
    "        pred_col: column name of the prediction (must be in df)\n",
    "    \n",
    "    Returns:\n",
    "        dask_cudf: Series representing the cumulative F1 score\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=['tpep_dropoff_datetime'], ascending=True)\n",
    "    numerator = (df['prediction'] & df[target_col]).cumsum()\n",
    "    precision_denominator = df['prediction'].cumsum()\n",
    "    recall_denominator = df[target_col].cumsum()\n",
    "    precision = numerator / precision_denominator\n",
    "    recall = numerator / recall_denominator\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "def get_daily_f1_score(partition):\n",
    "    numerator = (partition[target_col] & partition['prediction']).sum()\n",
    "    recall_denominator = partition[target_col].sum()\n",
    "    precision_denominator = partition['prediction'].sum()\n",
    "    precision = numerator / precision_denominator\n",
    "    recall = numerator / recall_denominator\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    partition['daily_f1'] = f1_score\n",
    "    return partition.sort_values(by='tpep_dropoff_datetime', ascending=False).head(1)[['day', 'rolling_f1', 'daily_f1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 6405008, Size: 0.903424059 GB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:28:15</td>\n",
       "      <td>2020-01-01 00:33:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:35:39</td>\n",
       "      <td>2020-01-01 00:43:04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:47:41</td>\n",
       "      <td>2020-01-01 00:53:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-01 00:55:23</td>\n",
       "      <td>2020-01-01 01:00:14</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2020-01-01 00:01:58</td>\n",
       "      <td>2020-01-01 00:04:16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>193.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0       1.0  2020-01-01 00:28:15   2020-01-01 00:33:03              1.0   \n",
       "1       1.0  2020-01-01 00:35:39   2020-01-01 00:43:04              1.0   \n",
       "2       1.0  2020-01-01 00:47:41   2020-01-01 00:53:52              1.0   \n",
       "3       1.0  2020-01-01 00:55:23   2020-01-01 01:00:14              1.0   \n",
       "4       2.0  2020-01-01 00:01:58   2020-01-01 00:04:16              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.2         1.0                  N         238.0         239.0   \n",
       "1            1.2         1.0                  N         239.0         238.0   \n",
       "2            0.6         1.0                  N         238.0         238.0   \n",
       "3            0.8         1.0                  N         238.0         151.0   \n",
       "4            0.0         1.0                  N         193.0         193.0   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0           1.0          6.0    3.0      0.5        1.47           0.0   \n",
       "1           1.0          7.0    3.0      0.5        1.50           0.0   \n",
       "2           1.0          6.0    3.0      0.5        1.00           0.0   \n",
       "3           1.0          5.5    0.5      0.5        1.36           0.0   \n",
       "4           2.0          3.5    0.5      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  \n",
       "0                    0.3         11.27                   2.5  \n",
       "1                    0.3         12.30                   2.5  \n",
       "2                    0.3         10.80                   2.5  \n",
       "3                    0.3          8.16                   0.0  \n",
       "4                    0.3          4.80                   0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2020-01.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "print(f\"Num rows: {len(taxi)}, Size: {taxi.memory_usage(deep=True).sum().compute() / 1e9} GB\")\n",
    "taxi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 6382762, Size: 0.357434672 GB\n"
     ]
    }
   ],
   "source": [
    "target_col = \"high_tip\"\n",
    "\n",
    "taxi_train = preprocess(df=taxi, target_col=target_col)\n",
    "print(f\"Num rows: {len(taxi_train)}, Size: {taxi_train.memory_usage(deep=True).sum().compute() / 1e9} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model on January 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 252 ms, sys: 5.38 ms, total: 258 ms\n",
      "Wall time: 23.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "progress('start-rf-rapids-dask-fit')\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, ignore_empty_partitions=True)\n",
    "\n",
    "rfc.fit(taxi_train[features], taxi_train[target_col])\n",
    "progress('finished-rf-rapids-dask-fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6681650475249482\n"
     ]
    }
   ],
   "source": [
    "# Metrics on train set\n",
    "\n",
    "preds = rfc.predict_proba(taxi_train[features])[1]\n",
    "# print(f'Accuracy: {rfc.score(taxi_train[features].compute(), taxi_train[target_col].compute())}')\n",
    "print(f'F1: {f1_score(taxi_train[target_col].compute().to_array(), preds.round().compute().to_array())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on February 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_feb = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2020-02.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "taxi_test = preprocess(taxi_feb, target_col=target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.6658098920024954\n"
     ]
    }
   ],
   "source": [
    "# Metric on test set\n",
    "\n",
    "preds = rfc.predict_proba(taxi_test[features])[1]\n",
    "print(f'F1: {f1_score(taxi_test[target_col].compute().to_array(), preds.round().compute().to_array())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate \"live\" inference on March\n",
    "\n",
    "As every new batch of points comes in, we make a prediction. We compute the rolling and daily F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load and sort the march dataframe\n",
    "\n",
    "taxi_march = dask_cudf.read_csv(\n",
    "    \"s3://nyc-tlc/trip data/yellow_tripdata_2020-03.csv\",\n",
    "    parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "    storage_options={\"anon\": True},\n",
    "    assume_missing=True,\n",
    ")\n",
    "\n",
    "taxi_inference = preprocess(taxi_march, target_col=target_col, start_date='2020-03-01', end_date='2020-03-31').sort_values(by=['tpep_dropoff_datetime'], ascending=True).reset_index(drop=True)\n",
    "taxi_inference['day'] = taxi_inference.tpep_dropoff_datetime.dt.day.to_dask_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions as a new column, compute rolling F1 score\n",
    "\n",
    "taxi_inference['predicted_prob'] = rfc.predict_proba(taxi_inference[features])[1]\n",
    "taxi_inference['prediction'] = taxi_inference['predicted_prob'].round().astype('int32')\n",
    "taxi_inference['rolling_f1'] = f1_streaming(taxi_inference, target_col, 'prediction')\n",
    "daily_f1 = taxi_inference.groupby('day').apply(get_daily_f1_score, meta={'day': int, 'rolling_f1': float, 'daily_f1': float})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrr}\\n\\\\toprule\\n{} &  day &  rolling\\\\_f1 &  daily\\\\_f1 \\\\\\\\\\n\\\\midrule\\n178123  &    1 &    0.576629 &  0.576629 \\\\\\\\\\n370840  &    2 &    0.633320 &  0.677398 \\\\\\\\\\n592741  &    3 &    0.649983 &  0.675877 \\\\\\\\\\n821398  &    4 &    0.659940 &  0.684125 \\\\\\\\\\n1064741 &    5 &    0.675841 &  0.722298 \\\\\\\\\\n1307013 &    6 &    0.682284 &  0.708181 \\\\\\\\\\n58517   &    7 &    0.668002 &  0.555498 \\\\\\\\\\n225439  &    8 &    0.659918 &  0.572543 \\\\\\\\\\n400352  &    9 &    0.660947 &  0.670717 \\\\\\\\\\n583448  &   10 &    0.661801 &  0.670428 \\\\\\\\\\n765578  &   11 &    0.663678 &  0.684011 \\\\\\\\\\n936075  &   12 &    0.667420 &  0.711109 \\\\\\\\\\n1070221 &   13 &    0.668812 &  0.691889 \\\\\\\\\\n1159620 &   14 &    0.666032 &  0.571661 \\\\\\\\\\n1219523 &   15 &    0.664177 &  0.564885 \\\\\\\\\\n1283501 &   16 &    0.663604 &  0.638491 \\\\\\\\\\n1328995 &   17 &    0.663178 &  0.635958 \\\\\\\\\\n1365063 &   18 &    0.662761 &  0.628822 \\\\\\\\\\n1394730 &   19 &    0.662613 &  0.648809 \\\\\\\\\\n1422146 &   20 &    0.662300 &  0.629325 \\\\\\\\\\n1438271 &   21 &    0.661760 &  0.534262 \\\\\\\\\\n1448533 &   22 &    0.661437 &  0.541612 \\\\\\\\\\n1462011 &   23 &    0.661225 &  0.611136 \\\\\\\\\\n1473783 &   24 &    0.660991 &  0.594909 \\\\\\\\\\n1484934 &   25 &    0.660754 &  0.590316 \\\\\\\\\\n1495523 &   26 &    0.660534 &  0.596606 \\\\\\\\\\n1507234 &   27 &    0.660228 &  0.576993 \\\\\\\\\\n1514827 &   28 &    0.659934 &  0.501860 \\\\\\\\\\n1520358 &   29 &    0.659764 &  0.537860 \\\\\\\\\\n1529847 &   30 &    0.659530 &  0.576178 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_f1.sort_values(by='day').compute().to_pandas().to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on later months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-03\n",
      "\tF1: 0.6592796100378214\n",
      "2020-04\n",
      "\tF1: 0.5714705472990737\n",
      "2020-05\n",
      "\tF1: 0.5530868473460906\n",
      "2020-06\n",
      "\tF1: 0.5967621469282887\n"
     ]
    }
   ],
   "source": [
    "# Cycle through many test sets\n",
    "\n",
    "months = ['2020-03', '2020-04', '2020-05', '2020-06']\n",
    "month_dfs = {}\n",
    "\n",
    "for month in months:\n",
    "    \n",
    "    if month not in month_dfs:\n",
    "        df = dask_cudf.read_csv(\n",
    "            f\"s3://nyc-tlc/trip data/yellow_tripdata_{month}.csv\",\n",
    "            parse_dates=[\"tpep_pickup_datetime\", \"tpep_dropoff_datetime\"],\n",
    "            storage_options={\"anon\": True},\n",
    "            assume_missing=True,\n",
    "        )\n",
    "\n",
    "        df = preprocess(df, target_col=target_col)\n",
    "        month_dfs[month] = df.copy()\n",
    "    \n",
    "    taxi_test = month_dfs[month]\n",
    "        \n",
    "    preds = rfc.predict_proba(taxi_test[features])[1]\n",
    "    print(month)\n",
    "#     print(f'\\tAccuracy: {rfc.score(taxi_test[features].compute(), taxi_test[target_col].compute())}')\n",
    "    print(f'\\tF1: {f1_score(taxi_test[target_col].compute().to_array(), preds.round().compute().to_array())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect differences between feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickup_weekday\n",
      "pickup_hour\n",
      "work_hours\n",
      "pickup_minute\n",
      "passenger_count\n",
      "trip_distance\n",
      "trip_time\n",
      "trip_speed\n",
      "PULocationID\n",
      "DOLocationID\n",
      "RatecodeID\n"
     ]
    }
   ],
   "source": [
    "statistics = []\n",
    "p_values = []\n",
    "\n",
    "for feature in features:\n",
    "    statistic, p_value = stats.ks_2samp(taxi_train[feature].compute().to_pandas(), taxi_test[feature].compute().to_pandas())\n",
    "    statistics.append(statistic)\n",
    "    p_values.append(p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>statistic</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pickup_weekday</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>work_hours</td>\n",
       "      <td>0.028587</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>trip_time</td>\n",
       "      <td>0.017205</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>trip_speed</td>\n",
       "      <td>0.035415</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pickup_hour</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>8.610133e-258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trip_distance</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>5.266602e-78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PULocationID</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>2.994877e-46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DOLocationID</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>2.157559e-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger_count</td>\n",
       "      <td>0.002947</td>\n",
       "      <td>2.634493e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RatecodeID</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>3.047481e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pickup_minute</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>8.861498e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  statistic        p_value\n",
       "0    pickup_weekday   0.046196   0.000000e+00\n",
       "2        work_hours   0.028587   0.000000e+00\n",
       "6         trip_time   0.017205   0.000000e+00\n",
       "7        trip_speed   0.035415   0.000000e+00\n",
       "1       pickup_hour   0.009676  8.610133e-258\n",
       "5     trip_distance   0.005312   5.266602e-78\n",
       "8      PULocationID   0.004083   2.994877e-46\n",
       "9      DOLocationID   0.003132   2.157559e-27\n",
       "4   passenger_count   0.002947   2.634493e-24\n",
       "10       RatecodeID   0.002616   3.047481e-19\n",
       "3     pickup_minute   0.000702   8.861498e-02"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame(data={'feature': features, 'statistic': statistics, 'p_value': p_values})\n",
    "comparison_df.sort_values(by='p_value', ascending=True).head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
